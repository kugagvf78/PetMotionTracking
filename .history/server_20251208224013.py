from flask import Flask, render_template, Response, jsonify
import cv2
import threading
import time
import os
from datetime import datetime
from ultralytics import YOLO

# ==================================================
# FLASK APP
# ==================================================
app = Flask(__name__)
LOG_FILE = "motion_log.txt"

# ==================================================
# LOAD YOLO COCO MODEL
# ==================================================
print("üîç Loading YOLO COCO model...")
PET_MODEL = YOLO("yolov8n.pt")   # ƒë·ªïi sang yolov8s.pt n·∫øu mu·ªën ƒë·ªô ch√≠nh x√°c cao h∆°n
PET_THRESHOLD = 0.25

# ==================================================
# GLOBAL SENSOR STATES
# ==================================================
last_pir = 0          # PIR t·ª´ ESP8266 (hi·ªán l√† default)
last_rfid = None      # RFID t·ª´ ESP8266 (default)
pet_detected_flag = False
behavior_score = 0

# ==================================================
# CAMERA SYSTEM
# ==================================================
camera = None
latest_frame = None
camera_lock = threading.Lock()
last_gray = None


def init_camera():
    """Th·ª≠ m·ªü camera b·∫±ng nhi·ªÅu backend."""
    global camera

    backends = [
        (cv2.CAP_DSHOW, "DirectShow"),
        (cv2.CAP_MSMF, "Media Foundation"),
        (0, "Default OpenCV")
    ]

    for backend, name in backends:
        print(f"üîç Th·ª≠ m·ªü camera b·∫±ng backend: {name}")
        try:
            cam = cv2.VideoCapture(0, backend) if backend != 0 else cv2.VideoCapture(0)

            if cam.isOpened():
                cam.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                cam.set(cv2.CAP_PROP_FPS, 20)
                cam.set(cv2.CAP_PROP_BUFFERSIZE, 1)

                ret, frame = cam.read()
                if ret:
                    print(f"‚úÖ Camera m·ªü th√†nh c√¥ng b·∫±ng {name}")
                    camera = cam
                    return True

                cam.release()

        except Exception as e:
            print("‚ùå Camera error:", e)

    print("‚ö† Kh√¥ng th·ªÉ m·ªü camera!")
    return False


def camera_loop():
    """Lu·ªìng x·ª≠ l√Ω camera ch√≠nh."""
    global latest_frame, last_gray
    global pet_detected_flag, behavior_score
    global camera   # üî• FIX quan tr·ªçng ƒë·ªÉ kh√¥ng l·ªói scope

    error_count = 0

    while True:
        try:
            # N·∫øu camera m·∫•t t√≠n hi·ªáu ‚Üí th·ª≠ m·ªü l·∫°i
            if camera is None or not camera.isOpened():
                print("üîÑ ƒêang th·ª≠ m·ªü l·∫°i camera...")
                init_camera()
                time.sleep(1)
                continue

            ret, frame = camera.read()
            if not ret or frame is None:
                error_count += 1
                print(f"‚ö† L·ªói ƒë·ªçc frame ({error_count}/10)")
                if error_count >= 10:
                    camera.release()
                    camera = None
                continue

            error_count = 0

            # ==================================================
            # MOTION DETECTION
            # ==================================================
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            gray = cv2.GaussianBlur(gray, (21, 21), 0)

            motion_detected = False

            if last_gray is None:
                last_gray = gray
            else:
                diff = cv2.absdiff(last_gray, gray)
                thresh = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)[1]
                thresh = cv2.dilate(thresh, None, iterations=2)

                contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

                for c in contours:
                    if cv2.contourArea(c) > 800:
                        motion_detected = True
                        x, y, w, h = cv2.boundingRect(c)
                        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)

                last_gray = gray

            # TƒÉng / gi·∫£m behavior score
            if motion_detected:
                log_motion()
                behavior_score = min(100, behavior_score + 5)
            else:
                behavior_score = max(0, behavior_score - 1)

            # ==================================================
            # YOLO PET DETECTION ‚Äî COCO MODEL
            # ==================================================
            pet_label = "Kh√¥ng th·∫•y"
            pet_conf = 0.00
            pet_detected_flag = False

            try:
                results = PET_MODEL.predict(frame, conf=PET_THRESHOLD, verbose=False)

                for r in results:
                    for box in r.boxes:
                        conf = float(box.conf[0])
                        cls = int(box.cls[0])
                        label = PET_MODEL.names[cls]

                        # Ch·ªâ nh·∫≠n dog/cat
                        if label not in ["dog", "cat"]:
                            continue

                        print("üê∂ YOLO DETECT:", label, conf)

                        if conf >= PET_THRESHOLD:
                            pet_label = label
                            pet_conf = conf
                            pet_detected_flag = True

                            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)
                            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 200, 255), 2)
                            cv2.putText(frame, f"{label} {conf:.2f}",
                                        (x1, y1 - 5),
                                        cv2.FONT_HERSHEY_SIMPLEX, 0.7,
                                        (0, 255, 255), 2)

            except Exception as e:
                print("üî• YOLO ERROR:", e)

            # Overlay text
            cv2.putText(frame, f"Pet: {pet_label} ({pet_conf:.2f})",
                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX,
                        0.7, (255, 200, 0), 2)

            # ==================================================
            # UPDATE STREAM FRAME
            # ==================================================
            with camera_lock:
                latest_frame = frame.copy()

        except Exception as e:
            print("‚ùå Camera loop error:", e)

        time.sleep(0.03)


# ==================================================
# LOGGING SYSTEM
# ==================================================
last_log_time = 0
LOG_COOLDOWN = 2


def log_motion():
    global last_log_time

    now = time.time()
    if now - last_log_time < LOG_COOLDOWN:
        return

    last_log_time = now
    msg = f"{datetime.now().strftime('%H:%M:%S')} - Chuy·ªÉn ƒë·ªông ƒë∆∞·ª£c ghi nh·∫≠n!"

    with open(LOG_FILE, "a", encoding="utf-8") as f:
        f.write(msg + "\n")

    print("üìå LOG:", msg)


# ==================================================
# VIDEO STREAM API
# ==================================================
def gen_frames():
    global latest_frame
    while True:
        with camera_lock:
            if latest_frame is None:
                continue
            frame = latest_frame.copy()

        ret, buffer = cv2.imencode(".jpg", frame)
        if not ret:
            continue

        yield (b"--frame\r\nContent-Type: image/jpeg\r\n\r\n" +
               buffer.tobytes() + b"\r\n")


# ==================================================
# SENSOR STATUS API (Dashboard c·∫ßn)
# ==================================================
@app.route("/sensor_status")
def sensor_status():
    return jsonify({
        "pir": last_pir,
        "rfid": last_rfid,
        "pet_detected": pet_detected_flag,
        "behavior_score": behavior_score
    })


# ==================================================
# CAMERA STATUS API
# ==================================================
@app.route("/camera_status")
def camera_status():
    return jsonify({
        "active": camera is not None and camera.isOpened(),
        "has_frame": latest_frame is not None
    })


# ==================================================
# MOTION STATS API
# ==================================================
@app.route("/motion_stats")
def motion_stats():
    if not os.path.exists(LOG_FILE):
        return jsonify([])

    stats = {}

    with open(LOG_FILE, "r", encoding="utf-8") as f:
        for line in f.readlines():
            if " - " in line:
                minute = line.split(" - ")[0][:5]
                stats[minute] = stats.get(minute, 0) + 1

    return jsonify([{"time": k, "count": v} for k, v in sorted(stats.items())])


# ==================================================
# GET LOGS API (Dashboard c·∫ßn)
# ==================================================
@app.route("/get_logs")
def get_logs():
    if not os.path.exists(LOG_FILE):
        return jsonify([])

    logs = []
    with open(LOG_FILE, "r", encoding="utf-8") as f:
        for line in f.readlines():
            logs.append(line.strip())

    return jsonify(logs)


# ==================================================
# DASHBOARD ROUTE
# ==================================================
@app.route("/")
def index():
    logs = []
    if os.path.exists(LOG_FILE):
        with open(LOG_FILE, "r", encoding="utf-8") as f:
            logs = [line.strip() for line in f.readlines()]
    return render_template("index.html", logs=logs)


@app.route("/video_feed")
def video_feed():
    return Response(gen_frames(),
                    mimetype="multipart/x-mixed-replace; boundary=frame")


# ==================================================
# START SERVER
# ==================================================
if __name__ == "__main__":
    print("üöÄ PET MONITOR STARTING...")
    init_camera()
    threading.Thread(target=camera_loop, daemon=True).start()
    app.run(debug=True, threaded=True, use_reloader=False)
